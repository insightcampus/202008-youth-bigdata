{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_mining_korean_ver.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN6rVK+/JFfev24DtKLAvSH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insightcampus/202008-youth-bigdata/blob/master/chae_won/text_mining_korean_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3dRElgbT_yW",
        "colab_type": "text"
      },
      "source": [
        "# <1> 텍스트 전처리 (Text Preprocessing)\n",
        "###### * 텍스트를 자연어 처리를 위해 용도에 맞도록 사전에 표준화 하는 작업\n",
        "######  * 텍스트 내 정보를 유지하고, 중복을 제거하여 분석 효율성을 높이기 위해 전처리를 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PukBPqPUTOI",
        "colab_type": "text"
      },
      "source": [
        "1. 토큰화 (Tokenizing)\n",
        "* 텍스트를 자연어 처리르 위해 분리\n",
        "* 토큰화는 단어별로 분리하는 '단어 토큰화'와 문장별로 분리하는 '문장 토큰화'로 구분한다. \n",
        "(이후 실습에서는 단어 토큰화를 '토큰화'로 통일해서 칭하도록 함)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWBZpjBrUg7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6ee7bf96-2463-4a3c-839d-9d81aee57888"
      },
      "source": [
        "text = \"인생은 모두가 함께하는 여행이다. 매일매일 사는 동안 우리가 할 수 있는 건 최선을 다해 이 멋진 여행을 만끽하는 것이다.\"\n",
        "print(text.split(' '))  # 공백을 기준으로 split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생은', '모두가', '함께하는', '여행이다.', '매일매일', '사는', '동안', '우리가', '할', '수', '있는', '건', '최선을', '다해', '이', '멋진', '여행을', '만끽하는', '것이다.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD645SglWcFi",
        "colab_type": "text"
      },
      "source": [
        "# 1) Konlpy란? \n",
        ": 다양한 형태소 분석, 태깅 라이브러리를 파이썬에서 쉽게 사용할 수 있도록 모아둔 패키지\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATQx8AweYgVx",
        "colab_type": "text"
      },
      "source": [
        "< 참고 1 > \n",
        "- 빠른 분석이 중요할 때 : 트위터(Twitter)\n",
        "- 정확한 품사 정보가 필요할 때 : 꼬꼬마(Kkma)\n",
        "- 정확성, 시간 모두 중요할 때 : 코모란(Komoran)\n",
        "\n",
        "< 참고 2 > \n",
        "위의 패키지가 공통적으로 사용할 수 있는 클래스\n",
        "- nouns : 명사 추출\n",
        "- morphs : 형태소 추출 \n",
        "- pos : 품사 부착 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEzBw8_lVR3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "5a4645d4-3b53-41bc-fd26-b47507fa7ec2"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, JPype1, colorama, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmTHJTOUXUPl",
        "colab_type": "text"
      },
      "source": [
        "# 2) Komoran(코모란) 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGwP2oLHUvf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "92bfbb5b-d5c4-4806-bfbe-2895f7a69c99"
      },
      "source": [
        "# 형태소(morphs) 단위로 토큰화\n",
        "from konlpy.tag import Komoran # 대문자 잘 지켜줘야 함 \n",
        "komoran = Komoran()\n",
        "komoran_tokens = komoran.morphs(text)\n",
        "print(komoran_tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하', '는', '여행', '이', '다', '.', '매일', '매일', '살', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '건', '최선', '을', '다', '하', '아', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcGbAEY0Z7yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e30d7599-ce65-499c-8ba4-81e5d1887ec0"
      },
      "source": [
        "# 명사(nouns) 단위로 토큰화 \n",
        "komoran_tokens = komoran.nouns(text) \n",
        "print(komoran_tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '모두', '여행', '동안', '수', '건', '최선', '여행', '만끽', '것']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA0u4sq_aNbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3b458239-f111-476a-fe25-26ac47dc33a3"
      },
      "source": [
        "# pos(품사) 단위로 토큰화 \n",
        "komoran_tag = komoran.pos(text) \n",
        "print(komoran_tag)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'NNG'), ('은', 'JX'), ('모두', 'NNG'), ('가', 'JKS'), ('함께', 'MAG'), ('하', 'XSV'), ('는', 'ETM'), ('여행', 'NNG'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'VV'), ('는', 'ETM'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'JKS'), ('하', 'VV'), ('ㄹ', 'ETM'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETM'), ('건', 'NNB'), ('최선', 'NNG'), ('을', 'JKO'), ('다', 'MAG'), ('하', 'XSV'), ('아', 'EC'), ('이', 'MM'), ('멋지', 'VA'), ('ㄴ', 'ETM'), ('여행', 'NNG'), ('을', 'JKO'), ('만끽', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhTgsBn6Xmr5",
        "colab_type": "text"
      },
      "source": [
        "# 3) Hannanum(한나눔) 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hffLwKTTXz2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ebd157a5-7d30-494c-d073-497a6595f078"
      },
      "source": [
        "from konlpy.tag import Hannanum\n",
        "hannanum = Hannanum() # 사용하기 편하게 변수 지정해주기\n",
        "hannanum_tokens = hannanum.morphs(text) # morphs(형태소) 단위로 토큰화\n",
        "print(hannanum_tokens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께하', '는', '여행', '이', '다', '.', '매일매일', '사', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '거', '은', '최선', '을', '다하', '어', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HxSVFfabh5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4420babf-42d4-4f59-e6cc-bfa0c70cdbd3"
      },
      "source": [
        "hannanum_tokens = hannanum.nouns(text)\n",
        "print(hannanum_tokens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '모두', '여행', '동안', '우리', '수', '거', '최선', '여행', '만끽', '것']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiUmtWQUbr9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "747dc629-2884-416a-8e53-d11a3624f10e"
      },
      "source": [
        "hannanum_tokens = hannanum.pos(text)\n",
        "print(hannanum_tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'N'), ('은', 'J'), ('모두', 'N'), ('가', 'J'), ('함께하', 'P'), ('는', 'E'), ('여행', 'N'), ('이', 'J'), ('다', 'E'), ('.', 'S'), ('매일매일', 'M'), ('사', 'P'), ('는', 'E'), ('동안', 'N'), ('우리', 'N'), ('가', 'J'), ('하', 'P'), ('ㄹ', 'E'), ('수', 'N'), ('있', 'P'), ('는', 'E'), ('거', 'N'), ('은', 'J'), ('최선', 'N'), ('을', 'J'), ('다하', 'P'), ('어', 'E'), ('이', 'M'), ('멋지', 'P'), ('ㄴ', 'E'), ('여행', 'N'), ('을', 'J'), ('만끽', 'N'), ('하', 'X'), ('는', 'E'), ('것', 'N'), ('이', 'J'), ('다', 'E'), ('.', 'S')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i26ePTJnY_g_",
        "colab_type": "text"
      },
      "source": [
        "# 4) Okt(=Twitter tokenizer) 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXhocJ2MY9ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d044c8bb-e18f-4328-b7c7-4d030215ee5d"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "okt_tokens = okt.morphs(text)\n",
        "print(okt_tokens)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하는', '여행', '이다', '.', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '을', '다해', '이', '멋진', '여행', '을', '만끽', '하는', '것', '이다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpaDNybCbzCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3ec5d149-cf56-4f1b-e412-ce24a8d6980f"
      },
      "source": [
        "okt_tokens = okt.nouns(text)\n",
        "print(okt_tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '모두', '여행', '매일', '동안', '우리', '수', '건', '최선', '다해', '이', '여행', '만끽', '것']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kLGxsdob50R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "68cc3f6b-73ad-4718-f3cd-f09737b98ccc"
      },
      "source": [
        "okt_tags= okt.pos(text)\n",
        "print(okt_tags)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'Noun'), ('은', 'Josa'), ('모두', 'Noun'), ('가', 'Josa'), ('함께', 'Adverb'), ('하는', 'Verb'), ('여행', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation'), ('매', 'Modifier'), ('일', 'Modifier'), ('매일', 'Noun'), ('사는', 'Verb'), ('동안', 'Noun'), ('우리', 'Noun'), ('가', 'Josa'), ('할', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('건', 'Noun'), ('최선', 'Noun'), ('을', 'Josa'), ('다해', 'Noun'), ('이', 'Noun'), ('멋진', 'Adjective'), ('여행', 'Noun'), ('을', 'Josa'), ('만끽', 'Noun'), ('하는', 'Verb'), ('것', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuPizB11Zbr6",
        "colab_type": "text"
      },
      "source": [
        "# 5) Kkma(꼬꼬마) 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdZVBZF1VECg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2c819a1a-c182-4cd6-80c0-f18e7bf949eb"
      },
      "source": [
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "kkma_tokens = kkma.morphs(text)\n",
        "print(kkma_tokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하', '는', '여행', '이', '다', '.', '매일', '매일', '살', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '것', '은', '최선', '을', '다하', '어', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJbsQn3KZ0L-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "571a610c-c0cd-4d0f-d2a0-4c61c3f97283"
      },
      "source": [
        "kkma_tokens = kkma.nouns(text)\n",
        "print(kkma_tokens)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '모두', '여행', '동안', '우리', '수', '최선', '만끽']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z5Qr-HFcCjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9f24f65b-5f55-4298-dfcf-044ad3655d29"
      },
      "source": [
        "kkma_tags = kkma.pos(text)\n",
        "print(kkma_tags)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'NNG'), ('은', 'JX'), ('모두', 'NNG'), ('가', 'JKS'), ('함께', 'MAG'), ('하', 'VV'), ('는', 'ETD'), ('여행', 'NNG'), ('이', 'VCP'), ('다', 'EFN'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'VV'), ('는', 'ETD'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'JKS'), ('하', 'VV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETD'), ('것', 'NNB'), ('은', 'JKS'), ('최선', 'NNG'), ('을', 'JKO'), ('다하', 'VV'), ('어', 'ECS'), ('이', 'MDT'), ('멋지', 'VA'), ('ㄴ', 'ETD'), ('여행', 'NNG'), ('을', 'JKO'), ('만끽', 'NNG'), ('하', 'XSV'), ('는', 'ETD'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EFN'), ('.', 'SF')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE8HnURGcHti",
        "colab_type": "text"
      },
      "source": [
        "# <2> 불용어 처리 (Stopword)\n",
        "\n",
        "\n",
        "* 자연어 처리를 위해 불필요한 요소를 제거하는 작업\n",
        "* 불필요한 품사를 제거&불필요한 단어를 제거\n",
        "* 불필요한 토큰을 제거해서 연산의 효율성 ↑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGch5OQcdGXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "3f096db0-012e-497f-ccf8-db4c573c041e"
      },
      "source": [
        "# Okt \n",
        "# 최빈어(=최다빈도어) 조회. 최빈어 조회를 통해 불용어 제거 대상을 선정\n",
        "\n",
        "from collections import Counter \n",
        "Counter(okt_tags).most_common()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('가', 'Josa'), 2),\n",
              " (('하는', 'Verb'), 2),\n",
              " (('여행', 'Noun'), 2),\n",
              " (('이다', 'Josa'), 2),\n",
              " (('.', 'Punctuation'), 2),\n",
              " (('을', 'Josa'), 2),\n",
              " (('인생', 'Noun'), 1),\n",
              " (('은', 'Josa'), 1),\n",
              " (('모두', 'Noun'), 1),\n",
              " (('함께', 'Adverb'), 1),\n",
              " (('매', 'Modifier'), 1),\n",
              " (('일', 'Modifier'), 1),\n",
              " (('매일', 'Noun'), 1),\n",
              " (('사는', 'Verb'), 1),\n",
              " (('동안', 'Noun'), 1),\n",
              " (('우리', 'Noun'), 1),\n",
              " (('할', 'Verb'), 1),\n",
              " (('수', 'Noun'), 1),\n",
              " (('있는', 'Adjective'), 1),\n",
              " (('건', 'Noun'), 1),\n",
              " (('최선', 'Noun'), 1),\n",
              " (('다해', 'Noun'), 1),\n",
              " (('이', 'Noun'), 1),\n",
              " (('멋진', 'Adjective'), 1),\n",
              " (('만끽', 'Noun'), 1),\n",
              " (('것', 'Noun'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_rSXYOKdVpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a17baf4a-b823-437a-ca4d-3ba567023627"
      },
      "source": [
        "# 불용어 처리 \n",
        "stopPos = ['Determiner','Adverb','Conjunction','PreEomi','Eomi',\n",
        "           'Suffix','Punctuation','Foreign','Alpha', 'Number','Unknown']\n",
        "stopWord = []\n",
        "word = []\n",
        "for tag in okt_tags:\n",
        "  if tag[1] not in stopPos:\n",
        "    if tag[0] not in stopWord : \n",
        "      word.append(tag[0])\n",
        "print(word)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '하는', '여행', '이다', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '을', '다해', '이', '멋진', '여행', '을', '만끽', '하는', '것', '이다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dtf3waIgzYG",
        "colab_type": "text"
      },
      "source": [
        "okt_tags는 현재 토큰화 된 텍스트와 각 텍스트의 품사가 붙여져 있는 리스트 형태다.tag[0]=text, tag[1]=pos 이므로 pos를 제거한 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DncARKfwfJW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "22c6565b-c0ea-4b39-b0f6-782e6f69265a"
      },
      "source": [
        "print(okt_tokens)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하는', '여행', '이다', '.', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '을', '다해', '이', '멋진', '여행', '을', '만끽', '하는', '것', '이다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZwbBYDPftVW",
        "colab_type": "text"
      },
      "source": [
        "지금까지 konlpy를 이용한 다양한 패키지를 통해 text를 토큰화했다. 정리해보면, Text Tokenizer에 익숙해지기 위해 \n",
        "* 1) nouns, morphs, pos 단위로 토큰화를 해보았다. \n",
        "* 2) 불용어 처리를 통해 불필요한 pos를 제거하고 원하는 text만 추출했다. \n",
        "\n",
        "\n",
        " 각 패키지 마다 장점과 단점이 있으니, 필요한 상황에 따라 유연하게 사용하면 좋을 듯 하다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqznKvRNfoxM",
        "colab_type": "text"
      },
      "source": [
        "**-- END. **"
      ]
    }
  ]
}