{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tool - jupyter notebook (python=3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [감성분석 실습1] Naive Bayes로 스팸메일 필터링\n",
    "- 새로운 메일이 왔는데 'happy weekend'가 포함되어 있을 경우, 이 메일은 긍정(1)인가, 부정(0)인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 직접 구현하기 (by 주한나)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love happy weekend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bore work job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bore weekend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy together</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mail  label\n",
       "0          i love you      1\n",
       "1  love happy weekend      1\n",
       "2       bore work job      0\n",
       "3          i hate you      0\n",
       "4        bore weekend      0\n",
       "5      happy together      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = pd.read_csv('C:/NLP_edu_files/naivebayes_example.csv')\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = input_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love you</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, love, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love happy weekend</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, happy, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bore work job</td>\n",
       "      <td>0</td>\n",
       "      <td>[bore, work, job]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate you</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, hate, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bore weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>[bore, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy together</td>\n",
       "      <td>1</td>\n",
       "      <td>[happy, together]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mail  label                   token\n",
       "0          i love you      1          [i, love, you]\n",
       "1  love happy weekend      1  [love, happy, weekend]\n",
       "2       bore work job      0       [bore, work, job]\n",
       "3          i hate you      0          [i, hate, you]\n",
       "4        bore weekend      0         [bore, weekend]\n",
       "5      happy together      1       [happy, together]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ls = []\n",
    "for i in range(len(docs)):\n",
    "     doc_ls.append(input_file.loc[i,'mail'].split())\n",
    "doc_ls\n",
    "docs['token'] = doc_ls\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'i': 0,\n",
       "             'love': 1,\n",
       "             'you': 2,\n",
       "             'happy': 3,\n",
       "             'weekend': 4,\n",
       "             'bore': 5,\n",
       "             'work': 6,\n",
       "             'job': 7,\n",
       "             'hate': 8,\n",
       "             'together': 9})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "word2id = defaultdict(lambda : len(word2id))\n",
    "for doc in doc_ls:\n",
    "    for token in doc:\n",
    "        word2id[token]        # token을 인덱스로 넣자\n",
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# docs.loc[docs['label']==1, 'token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word2id.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1단계. 각 단어들이 긍정, 부정 분류에 등장한 빈도수를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = np.zeros((len(word2id), 4))\n",
    "\n",
    "for token in word2id.keys():\n",
    "    for x in docs.loc[docs['label']==1, 'token']:\n",
    "        if token in x:\n",
    "            freq[word2id[token],0] += 1\n",
    "            \n",
    "for token in word2id.keys():\n",
    "    for x in docs.loc[docs['label']==0, 'token']:\n",
    "        if token in x:\n",
    "            freq[word2id[token],1] += 1           \n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2단계. 각 단어의 조건부확률 값을 구한다.\n",
    "- Laplace smoothing 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.11111111, 0.11111111],\n",
       "       [2.        , 0.        , 0.16666667, 0.05555556],\n",
       "       [1.        , 1.        , 0.11111111, 0.11111111],\n",
       "       [2.        , 0.        , 0.16666667, 0.05555556],\n",
       "       [1.        , 1.        , 0.11111111, 0.11111111],\n",
       "       [0.        , 2.        , 0.05555556, 0.16666667],\n",
       "       [0.        , 1.        , 0.05555556, 0.11111111],\n",
       "       [0.        , 1.        , 0.05555556, 0.11111111],\n",
       "       [0.        , 1.        , 0.05555556, 0.11111111],\n",
       "       [1.        , 0.        , 0.11111111, 0.05555556]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for token in word2id.keys():\n",
    "    i = word2id[token]\n",
    "    freq[i, 2] = (freq[i,0]+1)/(sum(freq[:,0])+len(word2id))\n",
    "    freq[i, 3] = (freq[i,1]+1)/(sum(freq[:,1])+len(word2id))\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3단계. 신규텍스트 주어졌을 때 긍/부정일 확률 계산\n",
    "- Underflow 방지 위한 로그 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500000000000001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = 'happy weekend'\n",
    "char = char.split()\n",
    "\n",
    "p_under_p = 0\n",
    "p_under_n = 0\n",
    "\n",
    "for token in char:\n",
    "    i = word2id[token]\n",
    "    p_under_p = p_under_p + np.log(freq[i,2])\n",
    "    p_under_n = p_under_n + np.log(freq[i,3])\n",
    "    \n",
    "p_under_p = np.exp(p_under_p + np.log(0.5)) # log값을 다시 원래값으로 돌려놓기\n",
    "p_under_n = np.exp(p_under_n + np.log(0.5))\n",
    "p_under = p_under_p + p_under_n\n",
    "p_top = p_under_p\n",
    "p = p_top/p_under\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4단계. 함수로 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PosOrNeg(char, num):\n",
    "    char = char.split()\n",
    "\n",
    "    p_under_p = 0\n",
    "    p_under_n = 0\n",
    "\n",
    "    for token in char:\n",
    "        i = word2id[token]\n",
    "        p_under_p = p_under_p + np.log(freq[i,2])\n",
    "        p_under_n = p_under_n + np.log(freq[i,3])\n",
    "    p_under_p = np.exp(p_under_p + np.log(0.5))\n",
    "    p_under_n = np.exp(p_under_n + np.log(0.5))\n",
    "    p_under = p_under_p + p_under_n\n",
    "    \n",
    "    if num == 1:\n",
    "        p_top = p_under_p\n",
    "    elif num == 0:\n",
    "        p_top = p_under_n\n",
    "    p = p_top/p_under\n",
    "    \n",
    "    print(\"{} 단어들이 {}일 확률은\".format(char, '긍정' if num==1 else '부정'),p*100,\"% 이다.\")\n",
    "    return (num, p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'weekend'] 단어들이 부정일 확률은 24.999999999999996 % 이다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.24999999999999997)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PosOrNeg('happy weekend', 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'weekend'] 단어들이 긍정일 확률은 75.00000000000001 % 이다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 0.7500000000000001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PosOrNeg('happy weekend', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 직접 구현하기 (by 김현진 선생님)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i love you' 1]\n",
      " ['love happy weekend' 1]\n",
      " ['bore work job' 0]\n",
      " ['i hate you' 0]\n",
      " ['bore weekend' 0]\n",
      " ['happy together' 1]]\n"
     ]
    }
   ],
   "source": [
    "# 다루기 쉽게 array 형태로 바꾸기\n",
    "training_set = np.array(input_file)\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문서별 토큰수(토큰 빈도수) 계산\n",
    "- 확률 계산을 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'happy': [0, 0], 'weekend': [0, 0]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  collections import defaultdict\n",
    "wordfreq = defaultdict(lambda : [0,0])\n",
    "wordfreq['happy']\n",
    "wordfreq['weekend']\n",
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'i': [1, 1],\n",
       "             'love': [2, 0],\n",
       "             'you': [1, 1],\n",
       "             'happy': [2, 0],\n",
       "             'weekend': [1, 1],\n",
       "             'bore': [0, 2],\n",
       "             'work': [0, 1],\n",
       "             'job': [0, 1],\n",
       "             'hate': [0, 1],\n",
       "             'together': [1, 0]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰별로 문서 내 빈도수 카운팅\n",
    "from  collections import defaultdict\n",
    "wordfreq = defaultdict(lambda : [0,0]) # lambda : 새로운 단어가 추가될 때 default를  [0,0]으로 하겠다. [긍정,부정]\n",
    "\n",
    "for doc, point in training_set:\n",
    "    words = doc.split()\n",
    "    for word in words:\n",
    "        if point == 1:\n",
    "            wordfreq[word][0] += 1 # 긍정인 경우 0번째 인덱스에 1 더하기\n",
    "        else:\n",
    "            wordfreq[word][1] += 1 # 부정인 경우 1번째 인덱스에 1 더하기\n",
    "            \n",
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 2, 1, 0, 0, 0, 0, 1]\n",
      "[1, 0, 1, 0, 1, 2, 1, 1, 1, 0]\n",
      "8 8\n"
     ]
    }
   ],
   "source": [
    "# 긍정/부정 빈도수 계산\n",
    "긍정전체토큰수 = []\n",
    "부정전체토큰수 = []\n",
    "for key, (cnt1,cnt0) in wordfreq.items():\n",
    "    긍정전체토큰수.append(int(cnt1))\n",
    "    부정전체토큰수.append(int(cnt0))\n",
    "print(긍정전체토큰수)\n",
    "print(부정전체토큰수)\n",
    "전체갯수_긍정 = sum(긍정전체토큰수)\n",
    "전체갯수_부정 = sum(부정전체토큰수)\n",
    "print(전체갯수_긍정, 전체갯수_부정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 긍정/부정 빈도수 계산_2\n",
    "pos_sum = 0\n",
    "neg_sum = 0\n",
    "for token in wordfreq.keys():\n",
    "    pos_sum = pos_sum + wordfreq[token][0]\n",
    "    neg_sum = pos_sum + wordfreq[token][0]\n",
    "a = pos_sum, neg_sum\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training : 토큰별 조건부 확률 계산\n",
    "- Laplace smoothing 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'i': [1, 1],\n",
       "             'love': [2, 0],\n",
       "             'you': [1, 1],\n",
       "             'happy': [2, 0],\n",
       "             'weekend': [1, 1],\n",
       "             'bore': [0, 2],\n",
       "             'work': [0, 1],\n",
       "             'job': [0, 1],\n",
       "             'hate': [0, 1],\n",
       "             'together': [1, 0]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'i': [0.1111111111111111, 0.1111111111111111],\n",
       "             'love': [0.16666666666666666, 0.05555555555555555],\n",
       "             'you': [0.1111111111111111, 0.1111111111111111],\n",
       "             'happy': [0.16666666666666666, 0.05555555555555555],\n",
       "             'weekend': [0.1111111111111111, 0.1111111111111111],\n",
       "             'bore': [0.05555555555555555, 0.16666666666666666],\n",
       "             'work': [0.05555555555555555, 0.1111111111111111],\n",
       "             'job': [0.05555555555555555, 0.1111111111111111],\n",
       "             'hate': [0.05555555555555555, 0.1111111111111111],\n",
       "             'together': [0.1111111111111111, 0.05555555555555555]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordprobs = defaultdict(lambda:[0,0])\n",
    "for key, (cnt1, cnt0) in wordfreq.items():\n",
    "    wordprobs[key][0] = (cnt1+1)/(전체갯수_긍정 + len(wordfreq))\n",
    "    wordprobs[key][1] = (cnt0+1)/(전체갯수_부정 + len(wordfreq))\n",
    "wordprobs   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify : 신규텍스트가 주어졌을 때 확률 계산\n",
    "- Underflow 방지 위한 로그 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'weekend']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "doc = \"happy weekend\"\n",
    "tokens = doc.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob1 0.009259259259259257\n",
      "prob0 0.0030864197530864183\n",
      "happy와 weekend가 새로운 메일에 포함되어 있을 경우, 긍정확률과 부정확률\n",
      "긍정확률 : 75.00000000000001%\n",
      "부정확률 : 24.999999999999996%\n"
     ]
    }
   ],
   "source": [
    "# 초기값을 모두 0으로 처리\n",
    "log_prob1 = log_prob0 = 0.0\n",
    "\n",
    "# 모든 단어에 대해 반복\n",
    "for word, (prob1, prob0) in wordprobs.items():\n",
    "    if word in tokens:\n",
    "        log_prob1 += math.log(prob1)\n",
    "        log_prob0 += math.log(prob0)\n",
    "log_prob1 += math.log(전체갯수_긍정/(전체갯수_긍정+전체갯수_부정))\n",
    "log_prob0 += math.log(전체갯수_부정/(전체갯수_부정+전체갯수_부정))\n",
    "\n",
    "prob1 = math.exp(log_prob1)\n",
    "print('prob1', prob1)\n",
    "prob0 = math.exp(log_prob0)\n",
    "print('prob0', prob0)\n",
    "print('happy와 weekend가 새로운 메일에 포함되어 있을 경우, 긍정확률과 부정확률')\n",
    "print(\"긍정확률 : {}%\".format(prob1/(prob1+prob0)*100))\n",
    "print(\"부정확률 : {}%\".format(prob0/(prob1+prob0)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'weekend'] 단어들이 긍정일 확률은 75.00000000000001 % 이다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 0.7500000000000001)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내 것이랑 비교하기\n",
    "PosOrNeg('happy weekend', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love happy weekend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bore work job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bore weekend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy together</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mail  label\n",
       "0          i love you      1\n",
       "1  love happy weekend      1\n",
       "2       bore work job      0\n",
       "3          i hate you      0\n",
       "4        bore weekend      0\n",
       "5      happy together      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_file = pd.read_csv('C:/NLP_edu_files/naivebayes_example.csv')\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love you', 'love happy weekend', 'bore work job', 'i hate you', 'bore weekend', 'happy together']\n",
      "[1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# sklearn에 사용가능하도록 list 형태로 변환\n",
    "X_train = list(input_file['mail'])\n",
    "Y_train = list(input_file['label'])\n",
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# CountVectorizer 선언\n",
    "count_vect = CountVectorizer()\n",
    "# fit and transform\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "# MultinomialNB 선언 and fit\n",
    "clf = MultinomialNB().fit(X_train_counts, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[0.25 0.75]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "print(clf.predict(count_vect.transform([\"happy weekend\"]))) \n",
    "# 확률 \n",
    "print(clf.predict_proba(count_vect.transform([\"happy weekend\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
