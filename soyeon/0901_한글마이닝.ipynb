{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0901_한글마이닝.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPE1Msy0Wg/7nv0rcEdEBwX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insightcampus/202008-youth-bigdata/blob/master/0901_%ED%95%9C%EA%B8%80%EB%A7%88%EC%9D%B4%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXMRPUnrRwy0",
        "colab_type": "text"
      },
      "source": [
        "## 프로그램 설치\n",
        "- 한글 분석은 영어와 달리 기본 패키지를 활용할 수 없다 \n",
        "- 따라서 형태소 분석을 위한 프로그램을 별도로 설치해주는 것이 필요하다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NalBnc5uR_hK",
        "colab_type": "text"
      },
      "source": [
        "### 1) MeCAB설치 _ Win용\n",
        "- C드라이브에 mecab폴더를 만든다\n",
        "- [다음](https://github.com/Pusnow/mecab-ko-msvc/releases/tag/release-0.9.2-msvc-3)에서 win버전에 맞는 파일을 다운받는다\n",
        "- 만들어놓은 mecab폴더에 다운 받은 파일들을 넣어준다\n",
        "- [다음](https://github.com/Pusnow/mecab-ko-dic-msvc/releases/tag/mecab-ko-dic-2.1.1-20180720-msvc)에서 첫번째 압축 파일을 다운받는다\n",
        "- [다음](https://github.com/Pusnow/mecab-python-msvc/releases/tag/mecab_python-0.996_ko_0.9.2_msvc-2)에서 파이썬 버전에 맞는 파일을 다운받은 뒤, 현재 주피터 노트북이 실행되고 있는 폴더에 넣어준다\n",
        "- 주피터 노트북이 실행되는 폴더에 파이썬 파일을 만들어 !pip install을 실행한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfQuG7URnFv8",
        "colab_type": "text"
      },
      "source": [
        "### 2) KoNLPy 설치 _ Win용\n",
        "- [다음](https://www.oracle.com/java/technologies/javase-downloads.html)에서 버전에 맞는 EXE파일을 다운로드 받는다\n",
        "- 다운받은 JAVA EXE파일을 실행해 설치한다\n",
        "- 내 컴퓨터 > 속성 > 고급 시스템 설정 > 환경변수 > 시스템 변수 > Path에서 다운받은 java의 폴더 경로를 추가한다\n",
        "- Visual Studio를 설치한다\n",
        "- [다음](https://www.lfd.uci.edu/~gohlke/pythonlibs/#jpype)에서 파이썬 버전에 맞는 JPype1을 다운받는다\n",
        "- 주피터 노트북에 파이썬 파일을 하나 만들어 !pip install을 실행, Jpype1을 설치한다\n",
        "- 이후 !pip install konlpy를 진행한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO68GgwUR06r",
        "colab_type": "text"
      },
      "source": [
        "## 텍스트 전처리\n",
        "- 텍스트를 자연어 처리를 위해 용도에 맞도록 표준화하는 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gI_G7SvR5ud",
        "colab_type": "text"
      },
      "source": [
        "### 1) 토큰화\n",
        "- 텍스트를 자연어 처리를 위해 분리 하는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzvIlL_RNlox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "0c3d8a50-c693-4a7e-b9f8-37c3cc46258e"
      },
      "source": [
        "text = '인생은 모두가 함께하는 여행이다. 매일매일 사는 동안 우리가 할 수 있는 건 최선을 다해 이 멋진 여행을 만끽하는 것이다'\n",
        "print(text.split()) #공백으로 토큰화_그러나 한글은 조사, 어미 등이 붙어있기 때문에 공백으로 토큰화는 좋지 않다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생은', '모두가', '함께하는', '여행이다.', '매일매일', '사는', '동안', '우리가', '할', '수', '있는', '건', '최선을', '다해', '이', '멋진', '여행을', '만끽하는', '것이다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZaOjKhdSW-R",
        "colab_type": "text"
      },
      "source": [
        "- 토큰화에 필요한 라이브러리를 다운받는다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsqzQbbNSJdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "908a99c3-9d94-40fa-fe1e-e1e55fdeb49d"
      },
      "source": [
        "!pip install konlpy #konlpy는 형태소 분석에 필요한 여러 패키지를 포함한 라이브러리다\n",
        "from konlpy.tag import Komoran\n",
        "from konlpy.tag import Hannanum\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS9Twfjgt6aH",
        "colab_type": "text"
      },
      "source": [
        "- 각 패키지에 들어가는 입력값이 Str타입임을 유의하자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez986D8YSPMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "cb9f2111-1df6-459c-d056-ee78591b2848"
      },
      "source": [
        "komoran = Komoran() #호출한 패키지는 사용을 위해 선언이 필수적으로 해주어야 한다\n",
        "komoran_tokens = komoran.morphs(text) #komoran의 morphs를 사용해 토큰화\n",
        "print(komoran_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하', '는', '여행', '이', '다', '.', '매일', '매일', '살', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '건', '최선', '을', '다', '하', '아', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjOCctYztsRN",
        "colab_type": "text"
      },
      "source": [
        "- 사용할 수 있는 옵션으로 morphs와 더불어 noun, pos 등이 있다\n",
        "  + noun은 명사만 추출\n",
        "  + pos는 품사 단위로 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm3-Y0xEuxUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "30e2bd9a-d026-4459-fb52-d2ea099aa591"
      },
      "source": [
        "komoran = Komoran() #호출한 패키지는 사용을 위해 선언이 필수적으로 해주어야 한다\n",
        "komoran_tokens = komoran.pos(text) #komoran의 morphs를 사용해 토큰화\n",
        "print(komoran_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'NNG'), ('은', 'JX'), ('모두', 'NNG'), ('가', 'JKS'), ('함께', 'MAG'), ('하', 'XSV'), ('는', 'ETM'), ('여행', 'NNG'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'VV'), ('는', 'ETM'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'JKS'), ('하', 'VV'), ('ㄹ', 'ETM'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETM'), ('건', 'NNB'), ('최선', 'NNG'), ('을', 'JKO'), ('다', 'MAG'), ('하', 'XSV'), ('아', 'EC'), ('이', 'MM'), ('멋지', 'VA'), ('ㄴ', 'ETM'), ('여행', 'NNG'), ('을', 'JKO'), ('만끽', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EC')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hlVIMJ5u2FX",
        "colab_type": "text"
      },
      "source": [
        "- 위처럼 pos를 사용하면 품사 정보도 한번에 추출 가능하다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YuSy6wFSh7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "af475dc5-580b-4307-ef36-c87a18146f89"
      },
      "source": [
        "hannanum = Hannanum()\n",
        "hannanum_tokens = hannanum.morphs(text)\n",
        "print(hannanum_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께하', '는', '여행', '이', '다', '.', '매일매일', '사', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '거', '은', '최선', '을', '다하', '어', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8yrbPWFuAeE",
        "colab_type": "text"
      },
      "source": [
        "- 위처럼 Komoran과 Hannanum은 세밀하게 토큰화를 진행한다\n",
        "- 즉 어간/어미 단위까지 구분해 토큰화가 이루어진다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFa3gbRS0gP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b1177d52-155f-45d4-ad09-d96b5e782a7a"
      },
      "source": [
        "okt = Okt()\n",
        "okt_tokens = okt.morphs(text)\n",
        "print(okt_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하는', '여행', '이다', '.', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '을', '다해', '이', '멋진', '여행', '을', '만끽', '하는', '것', '이다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2s8R0iEuNSm",
        "colab_type": "text"
      },
      "source": [
        "- Okt는 품사단위로 토큰화 하기 때문에 상대적으로 토큰화 단위가 크다\n",
        "- Okt는 SNS등에서 사용되는 이모티콘 등을 구분할 수 있다는 장점이 있다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTKmmgxmS5e-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2243b12b-b2bb-42e9-b3a9-41acec6fe7cf"
      },
      "source": [
        "kkma=Kkma()\n",
        "kkma_tokens = kkma.morphs(text)\n",
        "print(kkma_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하', '는', '여행', '이', '다', '.', '매일', '매일', '살', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '것', '은', '최선', '을', '다하', '어', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB2o9NUzTBRJ",
        "colab_type": "text"
      },
      "source": [
        "### 2) 품사부착\n",
        "- 각 토큰에 품사정보를 추가하여 분석시 불필요한 품사를 제거하거나 필요한 품사만 필터링한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdqarMPyS97m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d0417107-af3b-47bc-f6c5-4d61ec6293ee"
      },
      "source": [
        "komoranTag = []\n",
        "for token in komoran_tokens: #토큰화된 결과물은 리스트 형태이기 때문에 for문을 사용해 하나씩 꺼내는 과정이 필요\n",
        "  komoranTag += komoran.pos(token)\n",
        "print(komoranTag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'NNG'), ('은', 'NNP'), ('모두', 'MAG'), ('가', 'VV'), ('아', 'EC'), ('함께', 'MAG'), ('하', 'NNG'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('여행', 'NNG'), ('이', 'MM'), ('다', 'MAG'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'VV'), ('ㄹ', 'ETM'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'VV'), ('아', 'EC'), ('하', 'NNG'), ('ㄹ', 'NA'), ('수', 'NNB'), ('있', 'VV'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('건', 'NNB'), ('최선', 'NNP'), ('을', 'NNG'), ('다', 'MAG'), ('하', 'NNG'), ('아', 'IC'), ('이', 'MM'), ('멋', 'NNG'), ('지', 'NNB'), ('ㄴ', 'JX'), ('여행', 'NNG'), ('을', 'NNG'), ('만끽', 'NNP'), ('하', 'NNG'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('것', 'NNB'), ('이', 'MM'), ('다', 'MAG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2dEGj6dTTvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "52881279-18bc-44d8-ecb5-40b065c4de93"
      },
      "source": [
        "hannanumTag = []\n",
        "for token in hannanum_tokens:\n",
        "  hannanumTag += hannanum.pos(token)\n",
        "print(hannanumTag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'N'), ('은', 'N'), ('모두', 'M'), ('가', 'J'), ('함께하', 'P'), ('어', 'E'), ('늘', 'P'), ('ㄴ', 'E'), ('여행', 'N'), ('이', 'M'), ('다', 'M'), ('.', 'S'), ('매일매일', 'M'), ('사', 'N'), ('늘', 'P'), ('ㄴ', 'E'), ('동안', 'N'), ('우리', 'N'), ('가', 'J'), ('하', 'I'), ('ㄹ', 'N'), ('수', 'N'), ('있', 'N'), ('늘', 'P'), ('ㄴ', 'E'), ('것', 'N'), ('은', 'N'), ('최선', 'N'), ('을', 'N'), ('다하', 'P'), ('어', 'E'), ('어', 'N'), ('이', 'M'), ('멋지', 'N'), ('ㄴ', 'N'), ('여행', 'N'), ('을', 'N'), ('만끽', 'N'), ('하', 'I'), ('늘', 'P'), ('ㄴ', 'E'), ('것', 'N'), ('이', 'M'), ('다', 'M')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS0v4wKTTbG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "dcee62ce-87ac-40fe-c6a8-bcb3891e5d6e"
      },
      "source": [
        "oktTag = []\n",
        "for token in okt_tokens:\n",
        "  oktTag += okt.pos(token)\n",
        "print(oktTag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'Noun'), ('은', 'Noun'), ('모두', 'Noun'), ('가', 'Verb'), ('함께', 'Adverb'), ('하는', 'Verb'), ('여행', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation'), ('매', 'Noun'), ('일', 'Noun'), ('매일', 'Noun'), ('사는', 'Verb'), ('동안', 'Noun'), ('우리', 'Noun'), ('가', 'Verb'), ('할', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('건', 'Noun'), ('최선', 'Noun'), ('을', 'Josa'), ('다해', 'Noun'), ('이', 'Noun'), ('멋진', 'Adjective'), ('여행', 'Noun'), ('을', 'Josa'), ('만끽', 'Noun'), ('하는', 'Verb'), ('것', 'Noun'), ('이다', 'Josa')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reoo2GyaTjX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b7a95fe4-46b3-4947-f4e5-9c04a49788b2"
      },
      "source": [
        "kkmaTag =[]\n",
        "for token in kkma_tokens:\n",
        "  kkmaTag += kkma.pos(token)\n",
        "print(kkmaTag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('인생', 'NNG'), ('은', 'NNG'), ('모두', 'MAG'), ('가', 'NNG'), ('함께', 'MAG'), ('하', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('여행', 'NNG'), ('이', 'NNG'), ('다', 'NNG'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'NNG'), ('하', 'NNG'), ('ㄹ', 'NNG'), ('수', 'NNG'), ('있', 'VA'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('것', 'NNB'), ('은', 'NNG'), ('최선', 'NNG'), ('을', 'NNG'), ('다하', 'VV'), ('어', 'NNG'), ('이', 'NNG'), ('멋지', 'VA'), ('ㄴ', 'NNG'), ('여행', 'NNG'), ('을', 'NNG'), ('만끽', 'NNG'), ('하', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('것', 'NNB'), ('이', 'NNG'), ('다', 'NNG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOWjSRjmTsEX",
        "colab_type": "text"
      },
      "source": [
        "### 3) 불용어처리\n",
        "- 자연어 처리를 위해 불필요한 요소를 제거하는 작업\n",
        "- 불필요한 품사를 제거하거나 불필요한 단어를 제거하는 작업으로 구성된다\n",
        "- [품사정보](https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrcma6gxTrBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter #Counter는 갯수를 세주는 함수이다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRMGVkPFvaCR",
        "colab_type": "text"
      },
      "source": [
        "- 아래처럼 자주 나오는 단어들을 집계해보면, 불용어 목룍에 무엇을 추가해야하는지 알 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXEGAcFYT1-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "a7993dbf-ee87-4ce5-ea97-01a15463bc6d"
      },
      "source": [
        "Counter(oktTag).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('가', 'Verb'), 2),\n",
              " (('하는', 'Verb'), 2),\n",
              " (('여행', 'Noun'), 2),\n",
              " (('이다', 'Josa'), 2),\n",
              " (('을', 'Josa'), 2),\n",
              " (('인생', 'Noun'), 1),\n",
              " (('은', 'Noun'), 1),\n",
              " (('모두', 'Noun'), 1),\n",
              " (('함께', 'Adverb'), 1),\n",
              " (('.', 'Punctuation'), 1),\n",
              " (('매', 'Noun'), 1),\n",
              " (('일', 'Noun'), 1),\n",
              " (('매일', 'Noun'), 1),\n",
              " (('사는', 'Verb'), 1),\n",
              " (('동안', 'Noun'), 1),\n",
              " (('우리', 'Noun'), 1),\n",
              " (('할', 'Verb'), 1),\n",
              " (('수', 'Noun'), 1),\n",
              " (('있는', 'Adjective'), 1),\n",
              " (('건', 'Noun'), 1),\n",
              " (('최선', 'Noun'), 1),\n",
              " (('다해', 'Noun'), 1),\n",
              " (('이', 'Noun'), 1),\n",
              " (('멋진', 'Adjective'), 1),\n",
              " (('만끽', 'Noun'), 1),\n",
              " (('것', 'Noun'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUnAXi45T7AD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "22e0d914-26ad-4218-9c58-a087f68be0cd"
      },
      "source": [
        "stopPos = ['Determiner','Adverb','Conjunction','Josa','PreEomi','Eomi','Suffix','Punctuation',\n",
        "           'Foreign','Alpha','Number','Unknown']\n",
        "stopWord = []\n",
        "word = []\n",
        "for tag in oktTag:\n",
        "  if tag[1] not in stopPos:\n",
        "    if tag[0] not in stopWord:\n",
        "      word.append(tag[0])\n",
        "print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '하는', '여행', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '다해', '이', '멋진', '여행', '만끽', '하는', '것']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTQUxRUXUO5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "eecf81c1-cee6-4da5-81f2-3cdebebd9c52"
      },
      "source": [
        "print(okt_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인생', '은', '모두', '가', '함께', '하는', '여행', '이다', '.', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '을', '다해', '이', '멋진', '여행', '을', '만끽', '하는', '것', '이다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FCjxANVxP1K",
        "colab_type": "text"
      },
      "source": [
        "## 한글 텍스트 마이닝 실습\n",
        "- [뉴스](https://www.yna.co.kr/view/AKR20200204081000017?section=it/it)에서 유의미한 단어를 추출해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRzhr7-JxhjT",
        "colab_type": "text"
      },
      "source": [
        "### 1) 크롤링\n",
        "- 뉴스 페이지의 텍스트를 크롤링해 가져온다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP_7tn4gUXA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR4Cb-tqxtc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://www.yna.co.kr/view/AKR20200204081000017?section=it/it'\n",
        "page = requests.get(url)\n",
        "content = bs(page.text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW-e7b6cx4Yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "872daf40-b38b-4ebf-9865-d0f25c145dfb"
      },
      "source": [
        "news = content.find('div',class_='story-news article')\n",
        "txt = news.find_all('p')\n",
        "txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"txt-desc\">(서울=연합뉴스) 홍지인 기자 = 구글의 칼라 브롬버그 '공익을 위한 AI' 프로그램 리드가 4일 역삼동 구글코리아에서 화상 기자간담회를 갖고 있다. 2020. 2. 4.</p>,\n",
              " <p> (서울=연합뉴스) 홍지인 기자 = 구글은 인공지능(AI) 기술을 활용한 기상 예측 모델을 개발해 일부 분야에서는 미국 정부보다 더 뛰어난 예보 결과를 내놓고 있다고 4일 밝혔다.</p>,\n",
              " <p> 구글의 칼라 브롬버그 '공익을 위한 AI' 프로그램 리드는 이날 서울 역삼동 구글코리아에서 가진 화상 기자간담회에서 \"신경망을 이용한 기상 예측은 기존 예측 방법보다 훨씬 정확하다\"고 말했다. </p>,\n",
              " <p> 구글의 '나우캐스트' 기상 예측 모델은 6시간 이내 단기 예보에 초점을 맞추고 기상 레이더 관측 자료와 위성 사진 등을 모아 유넷(U-Net)이라는 신경망으로 계산한다.</p>,\n",
              " <p> 기존 모델로는 몇 시간이 걸리는 작업을 5~10분 만에 내놓을 수 있고, 공간 해상도도 1㎞로 미국 해양대기청(NOAA)의 예보모델 'HRRR'보다 10배 더 상세하다고 구글은 소개했다. </p>,\n",
              " <p> 예보 정확도 면에서는 1~3시간 단기예보의 경우도 HRRR보다 더 뛰어나다고 구글은 분석했다. 단, 5~6시간 이상 예보에서는 HRRR이 더 정확했다. </p>,\n",
              " <p> 칼라 리드는 \"지금 시점에서 당장 기상 예측 모델을 상용화할 계획은 없다\"며 \"머신러닝 기법을 이용해 얼마나 날씨를 정확하게 예측할 수 있는지에 대해 연구과제로만 삼고 있다\"고 말했다. </p>,\n",
              " <p> 함유근 전남대 지구환경과학부 교수는 이날 간담회에서 '합성곱 신경망 기법'(CNN·Convolutional Neural Network)을 응용한 엘니뇨 예측 모형을 소개했다.</p>,\n",
              " <p> 그가 개발한 엘니뇨 예측 모형은 향후 18개월 동안 70% 이상 정확도로 엘니뇨 발생 가능성을 맞출 수 있다. 기존 모델은 예능 가능 기간이 1년 정도였다고 함 교수는 소개했다. </p>,\n",
              " <p> 함 교수는 \"엘니뇨의 예측 성능이 18개월로 늘어나면 엘니뇨로 인해 발생하는 전 세계적인 곡물 가격 변동 등에 선제적으로 대응할 수 있게 된다\"고 설명했다.</p>,\n",
              " <p> ljungberg@yna.co.kr<br/></p>,\n",
              " <p class=\"txt-copyright adrs\"><em class=\"txt\">&lt;저작권자(c) 연합뉴스, 무단 전재-재배포 금지&gt;</em><span class=\"date\">2020/02/04 11:33 송고</span></p>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJQ8NxZhzkIX",
        "colab_type": "text"
      },
      "source": [
        "- 위의 결과에서 tag를 떼고 하나의 Str을 만들기 위해 For문을 활용한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvPNWaHnyeY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f1d85e05-3a7e-455b-a9c4-bf9e6f0479ee"
      },
      "source": [
        "text = ''\n",
        "for line in txt:\n",
        "  text += line.text\n",
        "text[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(서울=연합뉴스) 홍지인 기자 = 구글의 칼라 브롬버그 \\'공익을 위한 AI\\' 프로그램 리드가 4일 역삼동 구글코리아에서 화상 기자간담회를 갖고 있다. 2020. 2. 4. (서울=연합뉴스) 홍지인 기자 = 구글은 인공지능(AI) 기술을 활용한 기상 예측 모델을 개발해 일부 분야에서는 미국 정부보다 더 뛰어난 예보 결과를 내놓고 있다고 4일 밝혔다. 구글의 칼라 브롬버그 \\'공익을 위한 AI\\' 프로그램 리드는 이날 서울 역삼동 구글코리아에서 가진 화상 기자간담회에서 \"신경망을 이용한 기상 예측은 기존 예측 방법보다 훨씬 정확하다\"고 말했다.  구글의 \\'나우캐스트\\' 기상 예측 모델은 6시간 이내 단기 예보에 초점을 맞추고 기상 레이더 관측 자료와 위성 사진 등을 모아 유넷(U-Net)이라는 신경망으로 계산한다. 기존 모델로는 몇 시간이 걸리는 작업을 5~10분 만에 내놓을 수 있고, 공간 해상도도 1㎞로 미국 해양대기청(NOAA)의 예보모델 \\'HRRR\\'보다 10배 더 상세하다고 구글은 소'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FXHyFFy0NGu",
        "colab_type": "text"
      },
      "source": [
        "### 2) 토큰화\n",
        "- Mecab패키지를 import해 크롤링한 뉴스 텍스트의 토큰화를 진행한다\n",
        "- 구글 코랩에서는 Mecab이 원활하게 작동하지 않기 때문에 코드를 중심으로 작성하도록 하겠다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5MTF2yM0dSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx33CZ6-MEym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mecab = Mecab()\n",
        "mecab_tokens = mecab.morphs(text)\n",
        "print(mecab_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD2ANH7_QSwG",
        "colab_type": "text"
      },
      "source": [
        "- 위의 결과는 다음과 같이 출력된다\n",
        "``` python\n",
        "['(', '서울', '=', '연합뉴스', ')', '홍지인', '기자', '=', '구글', '의', '칼라', '브롬버그', \"'\", '공익', '을', '위한', 'AI', \"'\", '프로그램', '리드', '가', '4', '일', '역삼동', '구글', '코리아', '에서', '화상', '기자', '간담회', '를', '갖', '고', '있', '다', '.', '2020', '.', '2', '.', '4', '.', '(', '서울', '=', '연합뉴스', ')', '홍지인', '기자', '=', '구글', '은', '인공지능', '(', 'AI', ')', '기술', '을', '활용', '한', '기상', '예측', '모델', '을', '개발', '해', '일부', '분야', '에서', '는', '미국', '정부', '보다', '더', '뛰어난', '예보', '결과', '를', '내놓', '고', '있', '다고', '4', '일', '밝혔', '다', '.', '구글', '의', '칼라', '브롬버그', \"'\", '공익', '을', '위한', 'AI', \"'\", '프로그램', '리드', '는', '이날', '서울', '역삼동', '구글', '코리아', '에서', '가진', '화상', '기자', '간담회', '에서', '\"', '신경망', '을', '이용', '한', '기상', '예측', '은', '기존', '예측', '방법', '보다', '훨씬', '정확', '하', '다', '\"', '고', '말', '했', '다', '.', '구글', '의', \"'\", '나우', '캐스트', \"'\", '기상', '예측', '모델', '은', '6', '시간', '이내', '단기', '예보', '에', '초점', '을', '맞추', '고', '기상', '레이더', '관측', '자료', '와', '위성', '사진', '등', '을', '모아', '유', '넷', '(', 'U', '-', 'Net', ')', '이', '라는', '신경망', '으로', '계산', '한다', '.', '기존', '모델', '로', '는', '몇', '시간', '이', '걸리', '는', '작업', '을', '5', '~', '10', '분', '만', '에', '내놓', '을', '수', '있', '고', ',', '공간', '해상도', '도', '1', '㎞', '로', '미국', '해양', '대', '기청', '(', 'NOAA', ')', '의', '예보', '모델', \"'\", 'HRRR', \"'\", '보다', '10', '배', '더', '상세', '하', '다고', '구글', '은', '소개', '했', '다', '.', '예보', '정확', '도', '면', '에서', '는', '1', '~', '3', '시간', '단기', '예보', '의', '경우', '도', 'HRRR', '보다', '더', '뛰어나', '다고', '구글', '은', '분석', '했', '다', '.', '단', ',', '5', '~', '6', '시간', '이상', '예보', '에서', '는', 'HRRR', '이', '더', '정확', '했', '다', '.', '칼라', '리드', '는', '\"', '지금', '시점', '에서', '당장', '기상', '예측', '모델', '을', '상용', '화', '할', '계획', '은', '없', '다', '\"', '며', '\"', '머신', '러닝', '기법', '을', '이용', '해', '얼마나', '날씨', '를', '정확', '하', '게', '예측', '할', '수', '있', '는지', '에', '대해', '연구', '과제', '로', '만', '삼', '고', '있', '다', '\"', '고', '말', '했', '다', '.', '함유근', '전', '남대', '지구', '환경', '과', '학부', '교수', '는', '이날', '간담회', '에서', \"'\", '합성곱', '신경망', '기법', \"'(\", 'CNN', '·', 'Convolutional', 'Neural', 'Network', ')', '을', '응용', '한', '엘니뇨', '예측', '모형', '을', '소개', '했', '다', '.', '그', '가', '개발', '한', '엘니뇨', '예측', '모형', '은', '향후', '18', '개월', '동안', '70', '%', '이상', '정확도', '로', '엘니뇨', '발생', '가능', '성', '을', '맞출', '수', '있', '다', '.', '기존', '모델', '은', '예능', '가능', '기간', '이', '1', '년', '정도', '였', '다고', '함', '교수', '는', '소개', '했', '다', '.', '함', '교수', '는', '\"', '엘니뇨', '의', '예측', '성능', '이', '18', '개월', '로', '늘어나', '면', '엘니뇨', '로', '인해', '발생', '하', '는', '전', '세계', '적', '인', '곡물', '가격', '변동', '등', '에', '선제', '적', '으로', '대응', '할', '수', '있', '게', '된다', '\"', '고', '설명', '했', '다', '.', 'ljungberg', '@', 'yna', '.', 'co', '.', 'kr', '<', '저작권자', '(', 'c', ')', '연합뉴스', ',', '무단', '전재', '-', '재', '배포', '금지', '>', '2020', '/', '02', '/', '04', '11', ':', '33', '송고']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTMmLiSGQa57",
        "colab_type": "text"
      },
      "source": [
        "### 3) 품사 부착\n",
        "- 토큰화한 단어에 품사를 부착한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHCvQgmGQSOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mecabTag=[]\n",
        "for token in mecab_tokens:\n",
        "    mecabTag += mecab.pos(token)\n",
        "print(mecabTag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leKouWupQg5A",
        "colab_type": "text"
      },
      "source": [
        "- 위의 결과는 다음과 같다\n",
        "``` python\n",
        "[('(', 'SSO'), ('서울', 'NNP'), ('=', 'SY'), ('연합뉴스', 'NNP'), (')', 'SSC'), ('홍지인', 'NNP'), ('기자', 'NNG'), ('=', 'SY'), ('구글', 'NNG'), ('의', 'NNG'), ('칼라', 'NNG'), ('브롬버그', 'NNP'), (\"'\", 'SY'), ('공익', 'NNG'), ('을', 'JKO'), ('위한', 'VV+ETM'), ('AI', 'SL'), (\"'\", 'SY'), ('프로그램', 'NNG'), ('리드', 'NNP'), ('가', 'VV+EC'), ('4', 'SN'), ('일', 'NNG'), ('역삼동', 'NNP'), ('구글', 'NNG'), ('코리아', 'NNP'), ('에서', 'JKB'), ('화상', 'NNG'), ('기자', 'NNG'), ('간담회', 'NNG'), ('를', 'JKO'), ('갖', 'NNG'), ('고', 'EC'), ('있', 'VA'), ('다', 'MAG'), ('.', 'SF'), ('2020', 'SN'), ('.', 'SF'), ('2', 'SN'), ('.', 'SF'), ('4', 'SN'), ('.', 'SF'), ('(', 'SSO'), ('서울', 'NNP'), ('=', 'SY'), ('연합뉴스', 'NNP'), (')', 'SSC'), ('홍지인', 'NNP'), ('기자', 'NNG'), ('=', 'SY'), ('구글', 'NNG'), ('은', 'NNG'), ('인공지능', 'NNP'), ('(', 'SSO'), ('AI', 'SL'), (')', 'SSC'), ('기술', 'NNG'), ('을', 'JKO'), ('활용', 'NNG'), ('한', 'MM'), ('기상', 'NNG'), ('예측', 'NNG'), ('모델', 'NNG'), ('을', 'JKO'), ('개발', 'NNG'), ('해', 'VV+EC'), ('일부', 'NNG'), ('분야', 'NNG'), ('에서', 'JKB'), ('는', 'JX'), ('미국', 'NNP'), ('정부', 'NNG'), ('보', 'VV'), ('다', 'EC'), ('더', 'MAG'), ('뛰어난', 'VA+ETM'), ('예보', 'NNG'), ('결과', 'NNG'), ('를', 'JKO'), ('내', 'NP+JKG'), ('놓', 'NNG'), ('고', 'EC'), ('있', 'VA'), ('다고', 'EC'), ('4', 'SN'), ('일', 'NNG'), ('밝혔', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('구글', 'NNG'), ('의', 'NNG'), ('칼라', 'NNG'), ('브롬버그', 'NNP'), (\"'\", 'SY'), ('공익', 'NNG'), ('을', 'JKO'), ('위한', 'VV+ETM'), ('AI', 'SL'), (\"'\", 'SY'), ('프로그램', 'NNG'), ('리드', 'NNP'), ('는', 'JX'), ('이날', 'NNG'), ('서울', 'NNP'), ('역삼동', 'NNP'), ('구글', 'NNG'), ('코리아', 'NNP'), ('에서', 'JKB'), ('가진', 'VV+ETM'), ('화상', 'NNG'), ('기자', 'NNG'), ('간담회', 'NNG'), ('에서', 'JKB'), ('\"', 'SY'), ('신경망', 'NNG'), ('을', 'JKO'), ('이용', 'NNG'), ('한', 'MM'), ('기상', 'NNG'), ('예측', 'NNG'), ('은', 'NNG'), ('기존', 'NNG'), ('예측', 'NNG'), ('방법', 'NNG'), ('보', 'VV'), ('다', 'EC'), ('훨씬', 'MAG'), ('정확', 'NNG'), ('하', 'VV'), ('다', 'MAG'), ('\"', 'SY'), ('고', 'EC'), ('말', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('구글', 'NNG'), ('의', 'NNG'), (\"'\", 'SY'), ('나우', 'NNP'), ('캐스트', 'NNG'), (\"'\", 'SY'), ('기상', 'NNG'), ('예측', 'NNG'), ('모델', 'NNG'), ('은', 'NNG'), ('6', 'SN'), ('시간', 'NNG'), ('이내', 'NNG'), ('단기', 'NNG'), ('예보', 'NNG'), ('에', 'IC'), ('초점', 'NNG'), ('을', 'JKO'), ('맞추', 'VV'), ('고', 'EC'), ('기상', 'NNG'), ('레이더', 'NNG'), ('관측', 'NNG'), ('자료', 'NNG'), ('와', 'VV+EC'), ('위성', 'NNG'), ('사진', 'NNG'), ('등', 'NNG'), ('을', 'JKO'), ('모아', 'VV+EC'), ('유', 'NNP'), ('넷', 'NR'), ('(', 'SSO'), ('U', 'SL'), ('-', 'SY'), ('Net', 'SL'), (')', 'SSC'), ('이', 'MM'), ('라는', 'ETM'), ('신경망', 'NNG'), ('으로', 'JKB'), ('계산', 'NNG'), ('한다', 'VV+EC'), ('.', 'SF'), ('기존', 'NNG'), ('모델', 'NNG'), ('로', 'JKB'), ('는', 'JX'), ('몇', 'MM'), ('시간', 'NNG'), ('이', 'MM'), ('걸리', 'NNG'), ('는', 'JX'), ('작업', 'NNG'), ('을', 'JKO'), ('5', 'SN'), ('~', 'SY'), ('10', 'SN'), ('분', 'NNG'), ('만', 'JX'), ('에', 'IC'), ('내', 'NP+JKG'), ('놓', 'NNG'), ('을', 'JKO'), ('수', 'NNG'), ('있', 'VA'), ('고', 'EC'), (',', 'SC'), ('공간', 'NNG'), ('해상도', 'NNG'), ('도', 'NNG'), ('1', 'SN'), ('㎞', 'SY'), ('로', 'JKB'), ('미국', 'NNP'), ('해양', 'NNG'), ('대', 'NNG'), ('기청', 'NNG'), ('(', 'SSO'), ('NOAA', 'SL'), (')', 'SSC'), ('의', 'NNG'), ('예보', 'NNG'), ('모델', 'NNG'), (\"'\", 'SY'), ('HRRR', 'SL'), (\"'\", 'SY'), ('보', 'VV'), ('다', 'EC'), ('10', 'SN'), ('배', 'NNG'), ('더', 'MAG'), ('상세', 'NNG'), ('하', 'VV'), ('다고', 'EC'), ('구글', 'NNG'), ('은', 'NNG'), ('소개', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('예보', 'NNG'), ('정확', 'NNG'), ('도', 'NNG'), ('면', 'NNG'), ('에서', 'JKB'), ('는', 'JX'), ('1', 'SN'), ('~', 'SY'), ('3', 'SN'), ('시간', 'NNG'), ('단기', 'NNG'), ('예보', 'NNG'), ('의', 'NNG'), ('경우', 'NNG'), ('도', 'NNG'), ('HRRR', 'SL'), ('보', 'VV'), ('다', 'EC'), ('더', 'MAG'), ('뛰어나', 'VA+EC'), ('다고', 'EC'), ('구글', 'NNG'), ('은', 'NNG'), ('분석', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('단', 'MM'), (',', 'SC'), ('5', 'SN'), ('~', 'SY'), ('6', 'SN'), ('시간', 'NNG'), ('이상', 'NNG'), ('예보', 'NNG'), ('에서', 'JKB'), ('는', 'JX'), ('HRRR', 'SL'), ('이', 'MM'), ('더', 'MAG'), ('정확', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('칼라', 'NNG'), ('리드', 'NNP'), ('는', 'JX'), ('\"', 'SY'), ('지금', 'NNG'), ('시점', 'NNG'), ('에서', 'JKB'), ('당장', 'NNG'), ('기상', 'NNG'), ('예측', 'NNG'), ('모델', 'NNG'), ('을', 'JKO'), ('상용', 'NNG'), ('화', 'NNG'), ('할', 'VV+ETM'), ('계획', 'NNG'), ('은', 'NNG'), ('없', 'VA'), ('다', 'MAG'), ('\"', 'SY'), ('며', 'EC'), ('\"', 'SY'), ('머신', 'NNG'), ('러닝', 'NNG'), ('기법', 'NNG'), ('을', 'JKO'), ('이용', 'NNG'), ('해', 'VV+EC'), ('얼마나', 'MAG'), ('날씨', 'NNG'), ('를', 'JKO'), ('정확', 'NNG'), ('하', 'VV'), ('게', 'NNG'), ('예측', 'NNG'), ('할', 'VV+ETM'), ('수', 'NNG'), ('있', 'VA'), ('는지', 'EC'), ('에', 'IC'), ('대해', 'VV+EC'), ('연구', 'NNG'), ('과제', 'NNG'), ('로', 'JKB'), ('만', 'JX'), ('삼', 'NR'), ('고', 'EC'), ('있', 'VA'), ('다', 'MAG'), ('\"', 'SY'), ('고', 'EC'), ('말', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('함유근', 'NNP'), ('전', 'NNG'), ('남대', 'NNG'), ('지구', 'NNG'), ('환경', 'NNG'), ('과', 'NNG'), ('학부', 'NNG'), ('교수', 'NNG'), ('는', 'JX'), ('이날', 'NNG'), ('간담회', 'NNG'), ('에서', 'JKB'), (\"'\", 'SY'), ('합성곱', 'NNP'), ('신경망', 'NNG'), ('기법', 'NNG'), (\"'(\", 'SY'), ('CNN', 'SL'), ('·', 'SC'), ('Convolutional', 'SL'), ('Neural', 'SL'), ('Network', 'SL'), (')', 'SSC'), ('을', 'JKO'), ('응용', 'NNG'), ('한', 'MM'), ('엘니뇨', 'NNG'), ('예측', 'NNG'), ('모형', 'NNG'), ('을', 'JKO'), ('소개', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('그', 'MM'), ('가', 'VV+EC'), ('개발', 'NNG'), ('한', 'MM'), ('엘니뇨', 'NNG'), ('예측', 'NNG'), ('모형', 'NNG'), ('은', 'NNG'), ('향후', 'NNG'), ('18', 'SN'), ('개월', 'NNBC'), ('동안', 'NNG'), ('70', 'SN'), ('%', 'SY'), ('이상', 'NNG'), ('정확도', 'NNG'), ('로', 'JKB'), ('엘니뇨', 'NNG'), ('발생', 'NNG'), ('가능', 'NNG'), ('성', 'NNG'), ('을', 'JKO'), ('맞출', 'VV+ETM'), ('수', 'NNG'), ('있', 'VA'), ('다', 'MAG'), ('.', 'SF'), ('기존', 'NNG'), ('모델', 'NNG'), ('은', 'NNG'), ('예능', 'NNG'), ('가능', 'NNG'), ('기간', 'NNG'), ('이', 'MM'), ('1', 'SN'), ('년', 'NNG'), ('정도', 'NNG'), ('였', 'EP'), ('다고', 'EC'), ('함', 'NNG'), ('교수', 'NNG'), ('는', 'JX'), ('소개', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('함', 'NNG'), ('교수', 'NNG'), ('는', 'JX'), ('\"', 'SY'), ('엘니뇨', 'NNG'), ('의', 'NNG'), ('예측', 'NNG'), ('성능', 'NNG'), ('이', 'MM'), ('18', 'SN'), ('개월', 'NNBC'), ('로', 'JKB'), ('늘어나', 'VV+EC'), ('면', 'NNG'), ('엘니뇨', 'NNG'), ('로', 'JKB'), ('인해', 'VV+EC'), ('발생', 'NNG'), ('하', 'VV'), ('는', 'JX'), ('전', 'NNG'), ('세계', 'NNG'), ('적', 'NNG'), ('인', 'NNG'), ('곡물', 'NNG'), ('가격', 'NNG'), ('변동', 'NNG'), ('등', 'NNG'), ('에', 'IC'), ('선제', 'NNG'), ('적', 'NNG'), ('으로', 'JKB'), ('대응', 'NNG'), ('할', 'VV+ETM'), ('수', 'NNG'), ('있', 'VA'), ('게', 'NNG'), ('된다', 'VV+EC'), ('\"', 'SY'), ('고', 'EC'), ('설명', 'NNG'), ('했', 'VV+EP'), ('다', 'MAG'), ('.', 'SF'), ('ljungberg', 'SL'), ('@', 'SY'), ('yna', 'SL'), ('.', 'SF'), ('co', 'SL'), ('.', 'SF'), ('kr', 'SL'), ('<', 'SY'), ('저작권자', 'NNG'), ('(', 'SSO'), ('c', 'SL'), (')', 'SSC'), ('연합뉴스', 'NNP'), (',', 'SC'), ('무단', 'NNG'), ('전재', 'NNG'), ('-', 'SY'), ('재', 'XPN'), ('배포', 'NNG'), ('금지', 'NNG'), ('>', 'SY'), ('2020', 'SN'), ('/', 'SC'), ('02', 'SN'), ('/', 'SC'), ('04', 'SN'), ('11', 'SN'), (':', 'SC'), ('33', 'SN'), ('송고', 'NNP')]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMPEzifEQl9A",
        "colab_type": "text"
      },
      "source": [
        "### 4) 불용어 처리\n",
        "- Counter를 이용해 문장을 구성하는 단어와 품사를 살펴본 뒤 불용어를 선택해 필터링한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gikRGl8xQxDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "Counter(mecabTag).most_common()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I540TxZWQzLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopPos = ['SF','JKO','JX','SY','JKB','EC','EP','SSO','SSC','SN','SC',\n",
        "           'SL', 'JKS','JKC','JKG','JKB','JC','VV+EC','IC']\n",
        "stopWord = ['연합뉴스','홍지인','저작권자','기자','무단','전재','재','배포',\n",
        "            '금지','의','이','다','있','에','과','은','도','하','수','보','더',\n",
        "           '게','등']\n",
        "word = []\n",
        "for tag in mecabTag:\n",
        "    if tag[1] not in stopPos:\n",
        "        if tag[0] not in stopWord:\n",
        "              word.append(tag[0])\n",
        "print(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiW80G4pQ0O9",
        "colab_type": "text"
      },
      "source": [
        "- 위의 과정을 끝내면 다음과 같은 단어 목록을 얻을 수 있다\n",
        "``` python\n",
        "['서울', '구글', '칼라', '브롬버그', '공익', '위한', '프로그램', '리드', '일', '역삼동', '구글', '코리아', '화상', '간담회', '갖', '서울', '구글', '인공지능', '기술', '활용', '한', '기상', '예측', '모델', '개발', '일부', '분야', '미국', '정부', '뛰어난', '예보', '결과', '내', '놓', '일', '밝혔', '구글', '칼라', '브롬버그', '공익', '위한', '프로그램', '리드', '이날', '서울', '역삼동', '구글', '코리아', '가진', '화상', '간담회', '신경망', '이용', '한', '기상', '예측', '기존', '예측', '방법', '훨씬', '정확', '말', '했', '구글', '나우', '캐스트', '기상', '예측', '모델', '시간', '이내', '단기', '예보', '초점', '맞추', '기상', '레이더', '관측', '자료', '위성', '사진', '유', '넷', '라는', '신경망', '계산', '기존', '모델', '몇', '시간', '걸리', '작업', '분', '내', '놓', '공간', '해상도', '미국', '해양', '대', '기청', '예보', '모델', '배', '상세', '구글', '소개', '했', '예보', '정확', '면', '시간', '단기', '예보', '경우', '뛰어나', '구글', '분석', '했', '단', '시간', '이상', '예보', '정확', '했', '칼라', '리드', '지금', '시점', '당장', '기상', '예측', '모델', '상용', '화', '할', '계획', '없', '머신', '러닝', '기법', '이용', '얼마나', '날씨', '정확', '예측', '할', '연구', '과제', '삼', '말', '했', '함유근', '전', '남대', '지구', '환경', '학부', '교수', '이날', '간담회', '합성곱', '신경망', '기법', '응용', '한', '엘니뇨', '예측', '모형', '소개', '했', '그', '개발', '한', '엘니뇨', '예측', '모형', '향후', '개월', '동안', '이상', '정확도', '엘니뇨', '발생', '가능', '성', '맞출', '기존', '모델', '예능', '가능', '기간', '년', '정도', '함', '교수', '소개', '했', '함', '교수', '엘니뇨', '예측', '성능', '개월', '면', '엘니뇨', '발생', '전', '세계', '적', '인', '곡물', '가격', '변동', '선제', '적', '대응', '할', '설명', '했', '송고']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI9itL4gQ4r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}