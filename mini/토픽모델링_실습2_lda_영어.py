# -*- coding: utf-8 -*-
"""토픽모델링_실습2_LDA_영어.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15nXu10Wu8RoxbQYY86KiE5TaxYzPwHfv
"""

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
import pandas as pd
from sklearn.datasets import fetch_20newsgroups

# 뉴스 다운로드 및 전처리
def get_news(apply_split = True):
  # 20newsgroup 다운로드
  dataset = fetch_20newsgroups(shuffle= True, random_state=1, remove=('headers', 'footers','quotes'))
  documents = dataset.data

  news_df = pd.DataFrame({'document': documents})

  # 전처리
  news_df['clean_doc'] = news_df['document'].str.replace("[^a-zA-Z]"," ") # 특수 문자 제거
  news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x : ' '.join([w for w in x.split() if len(w)>3 ]) )
  news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x : x.lower()) # 전체 단어에 대한 소문자 변환
  tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화

  stop_words = stopwords.words('english') # NLTK 불용어 조회

  if apply_split:
    return tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])
  else :
    return tokenized_doc.apply(lambda x: ' '.join([item for item in x if item not in stop_words ]))

# 공백으로 토큰 분리
def my_tokenizer(text):
  return text.split()

tokenized_docs = get_news(False)

tokenized_docs

type(tokenized_docs)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import LatentDirichletAllocation

tfidf_vect = TfidfVectorizer(tokenizer = my_tokenizer)
tfidf = tfidf_vect.fit_transform(tokenized_docs)
# 모델 선언
lda =  LatentDirichletAllocation(n_components=20)
lda_output = lda.fit_transform(tfidf)

"""- 패키지 다운로드"""

!pip install matplotlib-venn

!apt-get -qq install -y libfluidsynth1

# To determine which version you're using:
!pip show tensorflow

# For the current version: 
!pip install --upgrade tensorflow

# For a specific version:
!pip install tensorflow==1.2

# For the latest nightly build:
!pip install tf-nightly

# https://pypi.python.org/pypi/libarchive
!apt-get -qq install -y libarchive-dev && pip install -U libarchive
import libarchive

# https://pypi.python.org/pypi/pydot
!apt-get -qq install -y graphviz && pip install pydot
import pydot

!apt-get -qq install python-cartopy python3-cartopy
import cartopy

!pip install pyLDAvis

import pyLDAvis
import pyLDAvis.sklearn

pyLDAvis.enable_notebook()
vis = pyLDAvis.sklearn.prepare(lda, tfidf, tfidf_vect, mds='tsne')
pyLDAvis.display(vis)